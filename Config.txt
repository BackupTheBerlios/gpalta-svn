#Sample config file for GPalta

populationSize = 500
nGenerations = 10000
    
tournamentSize = 2
    
maxDepth = 9
initialMinDepth = 3

#Upper limits for the probability regions of the tree operations. This means:
#probability of crossover = upLimitProbCrossOver - 0
#probability of mutation = upLimitProbMutation - upLimitProbCrossOver
#probability of reproduction = 1 - upLimitProbMutation

upLimitProbCrossOver = 0.85
upLimitProbMutation = 0.9
#The rest is for reproduction
    
constLowLimit = -100
constUpLimit = 100
    
maxCrossoverTries = 10

#Tree selection methods: tournament, roulette, proportional, SUS
selectionMethod = SUS
#SUS pointers distance:
pointerDistance = .01
    
upLimitProbSelectTerminal = .1
upLimitProbSelectNonTerminal = 1
upLimitProbSelectRoot = 0
#The rest is for select any node
    
probGrowBuild = .5
#The rest is for Full Build
    
#include previous outputs as inputs (how many)
nPreviousOutput = 0
#wheter previous outputs are real or logic nodes
usePreviousOutputAsReal = false

saveFileName = evo.bin

nodeConfigFileName = NodeConfig.txt

logFileName = log.txt
    
#On this mode, the system descends on the tree once and evaluates all fitness
#cases on a loop. On the contrary, when using normal evaluation, the system
#descends on the tree for each fitness case.
#The number of operations is the same, but vectorial evaluation should be
#faster when using lots of fitness cases.
#Note that with vectorial evaluation, all nodes on the tree are always
#evaluated. Instead, when using normal evaluation, sometimes the second kid
#doesn't need to be evaluated because the result can be determined using
#only the first kid (e.g on an "And" node if the first kid evals to zero)
#This could eventually lead to a slowdown instead of speeding things up,
#or cause problems when nodes have side effects (perform actions)
useVect = true

#If true, trees that haven't changed from the past generation will remember
#their fitness and won't be evaluated again.
#WARNING: do not use if some values change between generations (e.g. cicling
#fitness cases, random components in terminals, etc.)
rememberLastEval = false

problemType = generic
#problemType = classifier

#stop if fitness reaches this value:
stopFitness = 0.99

#For the clustering fitness:
nClasses = 5
useSoftPertenence = false

#For the classifier fitness:
    
#How much each SNR is more important than the next one:
#Must be smaller than 1/3
deltaSNR = 0.05

continuityImportance = 0.001

#How much important is voice over silence:
kHR1 = 4

usePreviousOutputAsReal = false

#These two for non interactive mode
nonInteractive = false
nDaysToRun = 1
